{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Napari workshop (June 29, 2022)\n",
    "\n",
    "This notebook will give you a practical introduction to the Napari viewer. To run the cells in sequence, use `Ctrl + Enter`.\n",
    "\n",
    "If you haven't installed napari yet, follow our [set-up guide]().\n",
    "\n",
    "If you run into troubles, don't hesitate to ask for help ðŸ¤šðŸ½."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Napari is a general-purpose N-dimensional image viewer based on Python.\n",
    "\n",
    "You can use it alongside your existing Python code and image analysis workflows, which may be based on scikit-image, Pytorch, Tensorflow, or any other Python library.\n",
    "\n",
    "It can be used alongside any Python library. For example, it can be coupled with scikit-image or machine learning libraries (Tensorflow, Pytorch ) to enable more user-friendly automated analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working from a Jupyter notebook, you have to run this \"magic\" command before starting napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to launch the Napari viewer in a seperate window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "napari.manifest -> 'btrack' could not be imported: Could not find file 'napari.yaml' in module 'btrack'\n",
      "/home/mallory/anaconda3/envs/napari-plugins/lib/python3.9/site-packages/napari_tools_menu/__init__.py:179: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load data into the viewer via the Jupyter notebook. The code below, for example, will first load an image into a numpy array, and then add it to the viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image of shape:  (256, 256)\n",
      "Added image to the viewer (check it!).\n"
     ]
    }
   ],
   "source": [
    "from skimage import data # Example data from scikit-image\n",
    "from skimage.io import imread\n",
    "\n",
    "# nuclei = data.cells3d()\n",
    "# nuclei = data.human_mitosis()\n",
    "nuclei = imread('/home/mallory/code/summer-school/example_data/nuclei.tif')[30]\n",
    "# nuclei = imread('/home/mallory/code/summer-school/napari-workshop/example_data/blobs.tif')\n",
    "print('Loaded image of shape: ', nuclei.shape)\n",
    "\n",
    "viewer.add_image(nuclei, name=\"nuclei\")\n",
    "print('Added image to the viewer (check it!).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the layers list, and the data in each layer, through `viewer.layers`. The layers are indexed by name (e.g. `viewer.layers['nuclei']`]) and numerically (e.g. `viewer.layers[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers list: \n",
      " [<Image layer 'nuclei' at 0x7f2e39e6cdf0>]\n",
      "\n",
      "Nuclei Image layer:  nuclei\n",
      "\n",
      "Nuclei Image data: \n",
      " [[0.13531114 0.10564399 0.08683068 ... 0.21273517 0.19536903 0.223589  ]\n",
      " [0.10853835 0.08393632 0.07959479 ... 0.25542692 0.20839363 0.23733719]\n",
      " [0.08900145 0.10926194 0.09044863 ... 0.24167873 0.25542692 0.26193922]\n",
      " ...\n",
      " [0.03835022 0.06005789 0.05209841 ... 0.05643994 0.06295224 0.06439942]\n",
      " [0.05065123 0.04992764 0.03835022 ... 0.05643994 0.05137482 0.04486252]\n",
      " [0.04775687 0.05788712 0.04920405 ... 0.04558611 0.05716353 0.0658466 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Layers list: \\n', viewer.layers)\n",
    "\n",
    "nuclei_layer = viewer.layers['nuclei']\n",
    "print('\\nNuclei Image layer: ', nuclei_layer)\n",
    "print('\\nNuclei Image data: \\n', nuclei_layer.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change properties of a layer and the viewer will update accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed layer lookup table to green.\n"
     ]
    }
   ],
   "source": [
    "nuclei_layer.colormap = 'green'  # Change the colormap to green\n",
    "\n",
    "print(f'Changed layer lookup table to {nuclei_layer.colormap.name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start processing our image. Our goal is to produce a segmentation of the `blobs`. We will import `numpy` and a few modules from `scikit-image` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good.\n"
     ]
    }
   ],
   "source": [
    "from skimage import morphology\n",
    "from skimage import feature\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import white_tophat, disk\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "\n",
    "print('All good.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we subtract the background of the image using the `white tophat` algorithm using a disk of radius 25 as a footprint.\n",
    "\n",
    "More info:\n",
    "https://en.wikipedia.org/wiki/Top-hat_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_layer.colormap = 'gray'  # Reset colormap\n",
    "\n",
    "# Compute the white tophat background subtraction\n",
    "background_subtracted_image = white_tophat(nuclei, footprint=disk(25))\n",
    "\n",
    "# Add the image after background subtraction to the viewer:\n",
    "viewer.add_image(background_subtracted_image, name='background subtracted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use Otsu's method to threshold the image. The result is a binary mask of the original image that separates the foreground (blobs) from the background.\n",
    "\n",
    "More info:\n",
    "https://en.wikipedia.org/wiki/Otsu%27s_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground = nuclei >= filters.threshold_otsu(background_subtracted_image)\n",
    "\n",
    "# Add the binary image as a Labels layer\n",
    "viewer.add_labels(foreground, name='Otsu binary mask');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the thresholding isn't perfect. We can clean-up the binary image by removing holes, as well as objects, below a certain size (in pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_processed = morphology.remove_small_holes(foreground, area_threshold=50)\n",
    "foreground_processed = morphology.remove_small_objects(foreground_processed, min_size=50)\n",
    "foreground_processed = morphology.erosion(foreground_processed)\n",
    "\n",
    "# Update the layer's data\n",
    "viewer.layers['Otsu binary mask'].data = foreground_processed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are interested in detecting a single seed point at the center of every blob. To do that, we first compute the `Euclidean distance transform` of our binary image, which gives an estimate, for each pixel, of its distance to the closest boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_img = ndimage.distance_transform_edt(foreground_processed)\n",
    "\n",
    "# Have a look at the distance image\n",
    "viewer.add_image(distance_img, name='Euclidean distance', colormap='viridis', opacity=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce irregularities, we apply a `Gaussian filter` to the distance image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_distance = filters.gaussian(distance_img, sigma=1)\n",
    "\n",
    "# Update the data in the layer\n",
    "viewer.layers['Euclidean distance'].data = smoothed_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect local maxima in the distance image to use them as seed points.\n",
    "\n",
    "More info on `peak_local_max`:\n",
    "https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.peak_local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225784/1018666243.py:1: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  peak_local_max = feature.peak_local_max(\n",
      "/home/mallory/anaconda3/envs/napari-plugins/lib/python3.9/site-packages/numpy/core/numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "peak_local_max = feature.peak_local_max(\n",
    "    smoothed_distance,\n",
    "    indices=False,\n",
    "    labels=measure.label(foreground_processed)\n",
    ")\n",
    "\n",
    "# Get the peask in the expected format\n",
    "peaks = np.array(np.nonzero(peak_local_max)).T\n",
    "\n",
    "# Display the detected peaks in a `Points` layer\n",
    "viewer.add_points(peaks, name='local peaks', size=4, face_color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to compute a watershed segmentation, using the detected peaks as seed (source) points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_to_markers(peaks):\n",
    "    \"\"\"Returns markers from peaks data\"\"\"\n",
    "    peaks_x, peaks_y = peaks.astype('int').T\n",
    "\n",
    "    seeds = np.zeros(nuclei.shape, dtype=bool)\n",
    "    seeds[(peaks_x, peaks_y)] = 1\n",
    "\n",
    "    # Label the marker points\n",
    "    markers = measure.label(seeds)\n",
    "    \n",
    "    return markers\n",
    "\n",
    "\n",
    "# If you edit the points manually, you can then start from the new peaks data here.\n",
    "peaks = viewer.layers['local peaks'].data\n",
    "\n",
    "markers = peaks_to_markers(peaks)\n",
    "\n",
    "# Watershed segmentation\n",
    "nuclei_segmentation = segmentation.watershed(\n",
    "    -smoothed_distance, \n",
    "    markers, \n",
    "    mask=foreground_processed\n",
    ")\n",
    "\n",
    "# Display the segmentation in a `Labels` layer\n",
    "viewer.add_labels(nuclei_segmentation, name='instance segmentation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Region properties\n",
    "\n",
    "If you wish to\n",
    "\n",
    "```bash\n",
    "pip install napari-regionprops-table\n",
    "```\n",
    "\n",
    "You should then be able to run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops_table\n",
    "from napari_skimage_regionprops import visualize_measurement_on_labels, add_table\n",
    "\n",
    "# Compute region properties\n",
    "statistics = regionprops_table(nuclei_segmentation, properties=['area'])\n",
    "\n",
    "# Add the statistics as properties of the Labels layer\n",
    "label_image = viewer.layers['instance segmentation']\n",
    "label_image.properties = statistics\n",
    "\n",
    "# Compute the parametric image\n",
    "parametric_image = visualize_measurement_on_labels(label_image, 'area')\n",
    "\n",
    "# Display the parametric image\n",
    "viewer.add_image(parametric_image, name=\"area\", colormap='jet');\n",
    "\n",
    "# Display a Table of area values\n",
    "add_table(label_image, viewer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well done!\n",
    "\n",
    "You have completed the introduction tutorial. To learn more about napari:\n",
    "\n",
    "Example data to play with:\n",
    "- [GH link]()\n",
    "\n",
    "\n",
    "[napari.org](https://napari.org/)\n",
    "[Documentation](https://napari.org/docs/)\n",
    "[Napari tutorials](https://napari.org/tutorials/)\n",
    "\n",
    "Further reading:\n",
    "- Adding custom functionality to the Napari interface using widgets (slider selectors, buttons, dropdown...)\n",
    "- Annotating data in Napari\n",
    "- The different layer types\n",
    "- Deep learning in Napari with Stardist / Cellpose\n",
    "  \n",
    "Do check out our [Napari Cheat Sheet]()\n",
    "\n",
    "We have curated a list of examples on using `Python`, `scikit-image` and `napari` in our [toolbox]().\n",
    "Check our `Napari toolbox` code:\n",
    "- Examples of every layer type\n",
    "- Imaging workflow boilerplates in scikit-image\n",
    "- Custom GUI elements and advanced interaction\n",
    "\n",
    "\n",
    "You can customize the interface and behaviour of the viewer by defining key bindings (keyboard shortcuts), adding mouse functions (controlling what clicking does), and creating little \"docking widgets\" that execute specific functions.\n",
    "\n",
    "[Image of a custom docking widget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f05481bea42030c9f519d66abf6edd269fd32d166c2623945fcb9c2214cfb730"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
